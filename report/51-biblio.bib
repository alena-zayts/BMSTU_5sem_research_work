@article{martin_muss_2021,
	title = {{MUSS}: Multilingual Unsupervised Sentence Simplification by Mining Paraphrases},
	url = {http://arxiv.org/abs/2005.00352},
	shorttitle = {{MUSS}},
	abstract = {Progress in sentence simplification has been hindered by a lack of labeled parallel simplification data, particularly in languages other than English. We introduce {MUSS}, a Multilingual Unsupervised Sentence Simplification system that does not require labeled simplification data. {MUSS} uses a novel approach to sentence simplification that trains strong models using sentence-level paraphrase data instead of proper simplification data. These models leverage unsupervised pretraining and controllable generation mechanisms to flexibly adjust attributes such as length and lexical complexity at inference time. We further present a method to mine such paraphrase data in any language from Common Crawl using semantic sentence embeddings, thus removing the need for labeled data. We evaluate our approach on English, French, and Spanish simplification benchmarks and closely match or outperform the previous best supervised results, despite not using any labeled simplification data. We push the state of the art further by incorporating labeled simplification data.},
	journaltitle = {{arXiv}:2005.00352 [cs]},
	author = {Martin, Louis and Fan, Angela and de la Clergerie, Éric and Bordes, Antoine and Sagot, Benoît},
	urldate = {2021-11-03},
	date = {2021-04-16},
	eprinttype = {arxiv},
	eprint = {2005.00352},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Martin et al_2021_MUSS.pdf:C\:\\Users\\alena\\Zotero\\storage\\422U6HDR\\Martin et al_2021_MUSS.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\alena\\Zotero\\storage\\73NM8YSC\\2005.html:text/html},
}

@inproceedings{see_get_2017,
	location = {Vancouver, Canada},
	title = {Get To The Point: Summarization with Pointer-Generator Networks},
	url = {https://aclanthology.org/P17-1099},
	doi = {10.18653/v1/P17-1099},
	shorttitle = {Get To The Point},
	abstract = {Neural sequence-to-sequence models have provided a viable new approach for abstractive text summarization (meaning they are not restricted to simply selecting and rearranging passages from the original text). However, these models have two shortcomings: they are liable to reproduce factual details inaccurately, and they tend to repeat themselves. In this work we propose a novel architecture that augments the standard sequence-to-sequence attentional model in two orthogonal ways. First, we use a hybrid pointer-generator network that can copy words from the source text via pointing, which aids accurate reproduction of information, while retaining the ability to produce novel words through the generator. Second, we use coverage to keep track of what has been summarized, which discourages repetition. We apply our model to the {CNN} / Daily Mail summarization task, outperforming the current abstractive state-of-the-art by at least 2 {ROUGE} points.},
	eventtitle = {{ACL} 2017},
	pages = {1073--1083},
	booktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	publisher = {Association for Computational Linguistics},
	author = {See, Abigail and Liu, Peter J. and Manning, Christopher D.},
	urldate = {2022-01-01},
	date = {2017-07},
	file = {Full Text PDF:files/66/See и др. - 2017 - Get To The Point Summarization with Pointer-Gener.pdf:application/pdf},
}

@article{paetzold_survey_2017,
	title = {A Survey on Lexical Simplification},
	volume = {60},
	rights = {Copyright (c)},
	issn = {1076-9757},
	url = {https://www.jair.org/index.php/jair/article/view/11091},
	doi = {10.1613/jair.5526},
	urldate = {2022-01-01},
	date = {2017-11-15},
	langid = {english},
}

@article{shardlow_survey_2014,
	title = {A Survey of Automated Text Simplification},
	volume = {4},
	doi = {10.14569/SpecialIssue.2014.040109},
	abstract = {Text simplification modifies syntax and lexicon to improve the understandability of language for an end user. This survey identifies and classifies simplification research within the period 1998-2013. Simplification can be used for many applications, including: Second language learners, preprocessing in pipelines and assistive technology. There are many approaches to the simplification task, including: lexical, syntactic, statistical machine translation and hybrid techniques. This survey also explores the current challenges which this field faces. Text simplification is a non-trivial task which is rapidly growing into its own field. This survey gives an overview of contemporary research whilst taking into account the history that has brought text simplification to its current state.},
	journaltitle = {International Journal of Advanced Computer Science and Applications},
	author = {Shardlow, Matthew},
	date = {2014-01-01},
	file = {Shardlow_2014_A Survey of Automated Text Simplification.pdf:C\:\\Users\\alena\\Zotero\\storage\\EIMG7NEG\\Shardlow_2014_A Survey of Automated Text Simplification.pdf:application/pdf},
}

@article{noauthor_nlp_nodate,
	title = {{NLP} From Scratch: Translation with a Sequence to Sequence Network and Attention — {PyTorch} Tutorials 1.10.1+cu102 documentation},
	url = {https://pytorch.org/tutorials/intermediate/seq2seq\_translation\_tutorial.html},
	urldate = {2022-01-01},
}

@article{rus_pas,
	title = {Валгина Н.С., Розенталь Д.Э., Фомина М.И. Современный русский язык: Учебник / Под редакцией Н.С. Вал},
	url = {https://pedlib.ru/Books/6/0262/6\_0262-288.shtml\#book\_page\_top},
	urldate = {2022-01-02},
	file = {Валгина Н.С., Розенталь Д.Э., Фомина М.И. Современный русский язык\: Учебник / Под редакцией Н.С. Вал:C\:\\Users\\alena\\Zotero\\storage\\2BRSKUXX\\6_0262-288.html:text/html},
}



@misc{chandrasekar_automatic_1997,
	title = {Automatic Induction of Rules for Text Simplification},
	abstract = {Long and complicated sentences pose various problems to many state-ofthe-art natural language technologies. We have been exploring methods to automatically transform such sentences in order to make them simpler. These methods involve the use of a rule-based system, driven by the syntax of the text in the domain of interest. Hand-crafting rules for every domain is time-consuming and impractical. The paper describes an algorithm and an implementation by which generalized rules for simpli-cation are automatically induced from annotated training material using a novel partial parsing technique which combines constituent structure and dependency information. The algorithm described in the paper employs example-based generalizations on linguistically-motivated structures.},
	author = {Chandrasekar, R. and Srinivas, B.},
	date = {1997},
	keywords = {first in synth},
	file = {Citeseer - Snapshot:C\:\\Users\\alena\\Zotero\\storage\\4L7WHMT5\\summary.html:text/html;Chandrasekar_Srinivas_1997_Automatic Induction of Rules for Text Simplification.pdf:C\:\\Users\\alena\\Zotero\\storage\\DIKIQGRC\\Chandrasekar_Srinivas_1997_Automatic Induction of Rules for Text Simplification.pdf:application/pdf},
}

@article{siddharthan_syntactic_2006,
	title = {Syntactic Simplification and Text Cohesion},
	volume = {4},
	issn = {1570-7075},
	url = {http://oro.open.ac.uk/58888/},
	abstract = {Syntactic simplification is the process of reducing the grammatical complexity of a text, while retaining its information content and meaning. The aim of syntactic simplification is to make text easier to comprehend for human readers, or process by programs. In this paper, we formalise the interactions that take place between syntax and discourse during the simplification process. This is important because the usefulness of syntactic simplification in making a text accessible to a wider audience can be undermined if the rewritten text lacks cohesion. We describe how various generation issues like sentence ordering, cue-word selection, referring-expression generation, determiner choice and pronominal use can be resolved so as to preserve conjunctive and anaphoric cohesive relations during syntactic simplification and present the results of an evaluation of our syntactic simplification system.},
	pages = {77--109},
	number = {1},
	journaltitle = {Research on Language and Computation},
	author = {Siddharthan, Advaith},
	urldate = {2022-01-02},
	date = {2006-06},
	langid = {english},
	note = {Number: 1
	Publisher: Springer Netherlands},
	file = {Snapshot:C\:\\Users\\alena\\Zotero\\storage\\ASP8HWAD\\58888.html:text/html},
}

@article{jonnalagadda_biosimplify_2010,
	title = {{BioSimplify}: an open source sentence simplification engine to improve recall in automatic biomedical information extraction},
	volume = {2010},
	issn = {1559-4076},
	url = {http://www.scopus.com/inward/record.url?scp=84964959827\&partnerID=8YFLogxK},
	shorttitle = {{BioSimplify}},
	abstract = {{BioSimplify} is an open source tool written in Java that introduces and facilitates the use of a novel model for sentence simplification tuned for automatic discourse analysis and information extraction (as opposed to sentence simplification for improving human readability). The model is based on a "shot-gun" approach that produces many different (simpler) versions of the original sentence by combining variants of its constituent elements. This tool is optimized for processing biomedical scientific literature such as the abstracts indexed in {PubMed}. We tested our tool on its impact to the task of {PPI} extraction and it improved the f-score of the {PPI} tool by around 7\%, with an improvement in recall of around 20\%. The {BioSimplify} tool and test corpus can be downloaded from https://biosimplify.sourceforge.net.},
	pages = {351--355},
	journaltitle = {{AMIA} ... Annual Symposium proceedings / {AMIA} Symposium. {AMIA} Symposium},
	author = {Jonnalagadda, Siddhartha and Gonzalez, Graciela},
	urldate = {2022-01-02},
	date = {2010-01-01},
}

@article{noauthor_svm_2017,
	title = {{SVM} {\textbar} Support Vector Machine Algorithm in Machine Learning},
	url = {https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/},
	abstract = {An introduction to Support Vector Machine Algorithm in Machine Learning. {SVM} tutorial explains classification and its implementation of {SVM} in R and Python.},
	titleaddon = {Analytics Vidhya},
	urldate = {2022-01-05},
	date = {2017-09-12},
	langid = {english},
	file = {Snapshot:C\:\\Users\\alena\\Zotero\\storage\\2Z57GP6A\\understaing-support-vector-machine-example-code.html:text/html},
}

@incollection{hutchison_ernesta_2013,
	location = {Berlin, Heidelberg},
	title = {{ERNESTA}: A Sentence Simplification Tool for Children’s Stories in Italian},
	volume = {7817},
	isbn = {978-3-642-37255-1 978-3-642-37256-8},
	url = {http://link.springer.com/10.1007/978-3-642-37256-8\_39},
	shorttitle = {{ERNESTA}},
	abstract = {We present {ERNESTA} (Enhanced Readability through a Novel Event-based Simpliﬁcation Tool), the ﬁrst sentence simpliﬁcation system for Italian, speciﬁcally developed to improve the comprehension of factual events in stories for children with low reading skills. The system performs two basic actions: First, it analyzes a text by resolving anaphoras (including null pronouns), so as to make all implicit information explicit. Then, it simpliﬁes the story sentence by sentence at syntactic level, by producing simple statements in the present tense on the factual events described in the story. Our simpliﬁcation strategy is driven by psycholinguistic principles and targets children aged 7 - 11 with text comprehension diﬃculties. The evaluation shows that our approach achieves promising results. Furthermore, {ERNESTA} could be exploited in diﬀerent tasks, for instance in the generation of educational games and reading comprehension tests.},
	pages = {476--487},
	booktitle = {Computational Linguistics and Intelligent Text Processing},
	publisher = {Springer Berlin Heidelberg},
	author = {Barlacchi, Gianni and Tonelli, Sara},
	editor = {Gelbukh, Alexander},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2022-01-05},
	date = {2013},
	langid = {english},
	doi = {10.1007/978-3-642-37256-8_39},
	note = {Series Title: Lecture Notes in Computer Science},
	file = {Barlacchi и Tonelli - 2013 - ERNESTA A Sentence Simplification Tool for Childr.pdf:C\:\\Users\\alena\\Zotero\\storage\\E9N97C2E\\Barlacchi и Tonelli - 2013 - ERNESTA A Sentence Simplification Tool for Childr.pdf:application/pdf},
}


@article{alva-manchego_data-driven_2020,
	title = {Data-Driven Sentence Simplification: Survey and Benchmark},
	volume = {46},
	issn = {0891-2017},
	url = {https://doi.org/10.1162/coli_a_00370},
	doi = {10.1162/coli_a_00370},
	shorttitle = {Data-Driven Sentence Simplification},
	abstract = {Sentence Simplification ({SS}) aims to modify a sentence in order to make it easier
	to read and understand. In order to do so, several rewriting transformations can
	be performed such as replacement, reordering, and splitting. Executing these
	transformations while keeping sentences grammatical, preserving their main idea,
	and generating simpler output, is a challenging and still far from solved
	problem. In this article, we survey research on {SS}, focusing on approaches that
	attempt to learn how to simplify using corpora of aligned original-simplified
	sentence pairs in English, which is the dominant paradigm nowadays. We also
	include a benchmark of different approaches on common data sets so as to compare
	them and highlight their strengths and limitations. We expect that this survey
	will serve as a starting point for researchers interested in the task and help
	spark new ideas for future developments.},
	pages = {135--187},
	number = {1},
	journaltitle = {Computational Linguistics},
	author = {Alva-Manchego, Fernando and Scarton, Carolina and Specia, Lucia},
	urldate = {2022-01-05},
	date = {2020},
	file = {Alva-Manchego et al_2020_Data-Driven Sentence Simplification.pdf:C\:\\Users\\alena\\Zotero\\storage\\Z2JA8F93\\Alva-Manchego et al_2020_Data-Driven Sentence Simplification.pdf:application/pdf;Snapshot:C\:\\Users\\alena\\Zotero\\storage\\QNJ6DYR2\\Data-Driven-Sentence-Simplification-Survey-and.html:text/html},
}


@inproceedings{aluisio_fostering_2010,
	location = {Los Angeles, California},
	title = {Fostering Digital Inclusion and Accessibility: The {PorSimples} project for Simplification of Portuguese Texts},
	url = {https://aclanthology.org/W10-1607},
	shorttitle = {Fostering Digital Inclusion and Accessibility},
	pages = {46--53},
	booktitle = {Proceedings of the {NAACL} {HLT} 2010 Young Investigators Workshop on Computational Approaches to Languages of the Americas},
	publisher = {Association for Computational Linguistics},
	author = {Aluísio, Sandra and Gasperin, Caroline},
	urldate = {2022-01-05},
	date = {2010},
	file = {Aluísio_Gasperin_2010_Fostering Digital Inclusion and Accessibility.pdf:C\:\\Users\\alena\\Zotero\\storage\\QE4SNDJ4\\Aluísio_Gasperin_2010_Fostering Digital Inclusion and Accessibility.pdf:application/pdf},
}


@article{deep,
	title = {A Review on Deep Learning Techniques Applied to Semantic Segmentation},
	url = {http://arxiv.org/abs/1704.06857},
	abstract = {Image semantic segmentation is more and more being of interest for computer vision and machine learning researchers. Many applications on the rise need accurate and efficient segmentation mechanisms: autonomous driving, indoor navigation, and even virtual or augmented reality systems to name a few. This demand coincides with the rise of deep learning approaches in almost every field or application target related to computer vision, including semantic segmentation or scene understanding. This paper provides a review on deep learning methods for semantic segmentation applied to various application areas. Firstly, we describe the terminology of this field as well as mandatory background concepts. Next, the main datasets and challenges are exposed to help researchers decide which are the ones that best suit their needs and their targets. Then, existing methods are reviewed, highlighting their contributions and their significance in the field. Finally, quantitative results are given for the described methods and the datasets in which they were evaluated, following up with a discussion of the results. At last, we point out a set of promising future works and draw our own conclusions about the state of the art of semantic segmentation using deep learning techniques.},
	journaltitle = {{arXiv}:1704.06857 [cs]},
	author = {Garcia-Garcia, Alberto and Orts-Escolano, Sergio and Oprea, Sergiu and Villena-Martinez, Victor and Garcia-Rodriguez, Jose},
	urldate = {2022-01-05},
	date = {2017-04-22},
	eprinttype = {arxiv},
	eprint = {1704.06857},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	file = {Garcia-Garcia et al_2017_A Review on Deep Learning Techniques Applied to Semantic Segmentation.pdf:C\:\\Users\\alena\\Zotero\\storage\\JXTJXY96\\Garcia-Garcia et al_2017_A Review on Deep Learning Techniques Applied to Semantic Segmentation.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\alena\\Zotero\\storage\\J7MBTHRP\\1704.html:text/html},
}


@article{wang_experimental_2016,
	title = {An Experimental Study of {LSTM} Encoder-Decoder Model for Text Simplification},
	url = {http://arxiv.org/abs/1609.03663},
	abstract = {Text simplification ({TS}) aims to reduce the lexical and structural complexity of a text, while still retaining the semantic meaning. Current automatic {TS} techniques are limited to either lexical-level applications or manually defining a large amount of rules. Since deep neural networks are powerful models that have achieved excellent performance over many difficult tasks, in this paper, we propose to use the Long Short-Term Memory ({LSTM}) Encoder-Decoder model for sentence level {TS}, which makes minimal assumptions about word sequence. We conduct preliminary experiments to find that the model is able to learn operation rules such as reversing, sorting and replacing from sequence pairs, which shows that the model may potentially discover and apply rules such as modifying sentence structure, substituting words, and removing words for {TS}.},
	journaltitle = {{arXiv}:1609.03663 [cs]},
	author = {Wang, Tong and Chen, Ping and Amaral, Kevin and Qiang, Jipeng},
	urldate = {2022-01-05},
	date = {2016-09-12},
	eprinttype = {arxiv},
	eprint = {1609.03663},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Wang et al_2016_An Experimental Study of LSTM Encoder-Decoder Model for Text Simplification.pdf:C\:\\Users\\alena\\Zotero\\storage\\V7AC4VY6\\Wang et al_2016_An Experimental Study of LSTM Encoder-Decoder Model for Text Simplification.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\alena\\Zotero\\storage\\RN5JDS88\\1609.html:text/html},
}

@article{nisioi_exploring_2017,
	location = {Vancouver, Canada},
	title = {Exploring Neural Text Simplification Models},
	url = {https://aclanthology.org/P17-2014},
	doi = {10.18653/v1/P17-2014},
	abstract = {We present the first attempt at using sequence to sequence neural networks to model text simplification ({TS}). Unlike the previously proposed automated {TS} systems, our neural text simplification ({NTS}) systems are able to simultaneously perform lexical simplification and content reduction. An extensive human evaluation of the output has shown that {NTS} systems achieve almost perfect grammaticality and meaning preservation of output sentences and higher level of simplification than the state-of-the-art automated {TS} systems},
	eventtitle = {{ACL} 2017},
	pages = {85--91},
	booktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
	publisher = {Association for Computational Linguistics},
	author = {Nisioi, Sergiu and Štajner, Sanja and Ponzetto, Simone Paolo and Dinu, Liviu P.},
	urldate = {2022-01-05},
	date = {2017},
	file = {Nisioi et al_2017_Exploring Neural Text Simplification Models.pdf:C\:\\Users\\alena\\Zotero\\storage\\TJQBUAVN\\Nisioi et al_2017_Exploring Neural Text Simplification Models.pdf:application/pdf},
}

@article{zhang_sentence_2017,
	location = {Copenhagen, Denmark},
	title = {Sentence Simplification with Deep Reinforcement Learning},
	url = {https://aclanthology.org/D17-1062},
	doi = {10.18653/v1/D17-1062},
	abstract = {Sentence simplification aims to make sentences easier to read and understand. Most recent approaches draw on insights from machine translation to learn simplification rewrites from monolingual corpora of complex and simple sentences. We address the simplification problem with an encoder-decoder model coupled with a deep reinforcement learning framework. Our model, which we call {DRESS} (as shorthand for Deep {REinforcement} Sentence Simplification), explores the space of possible simplifications while learning to optimize a reward function that encourages outputs which are simple, fluent, and preserve the meaning of the input. Experiments on three datasets demonstrate that our model outperforms competitive simplification systems.},
	eventtitle = {{EMNLP} 2017},
	pages = {584--594},
	booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
	publisher = {Association for Computational Linguistics},
	author = {Zhang, Xingxing and Lapata, Mirella},
	urldate = {2022-01-06},
	date = {2017},
	file = {Zhang_Lapata_2017_Sentence Simplification with Deep Reinforcement Learning.pdf:C\:\\Users\\alena\\Zotero\\storage\\SAF5TP78\\Zhang_Lapata_2017_Sentence Simplification with Deep Reinforcement Learning.pdf:application/pdf},
}

@ARTICLE{likert,
	author = {отв. ред. Г. В. Осипов, Л. Н. Москвичев; уч. секр. О. Е. Чернощек. },
	title = {Косолапов М.С. Шкала Лайкерта (Ликерта). Социологический словарь},
	year = {2015},
	journal = {М.: Академический учебно-научный центр РАН-МГУ им. М.В. Ломоносова, НОРМА, НИЦ ИНФРА М},
	pages = {372--373},
	
}



@article{xu_optimizing_2016,
	title = {Optimizing Statistical Machine Translation for Text Simplification},
	volume = {4},
	issn = {2307-387X},
	url = {https://doi.org/10.1162/tacl\_a\_00107},
	doi = {10.1162/tacl\_a\_00107},
	abstract = {Most recent sentence simplification systems use basic machine translation models
	to learn lexical and syntactic paraphrases from a manually simplified parallel
	corpus. These methods are limited by the quality and quantity of manually
	simplified corpora, which are expensive to build. In this paper, we conduct an
	in-depth adaptation of statistical machine translation to perform text
	simplification, taking advantage of large-scale paraphrases learned from
	bilingual texts and a small amount of manual simplifications with multiple
	references. Our work is the first to design automatic metrics that are effective
	for tuning and evaluating simplification systems, which will facilitate
	iterative development for this task.},
	pages = {401--415},
	journaltitle = {Transactions of the Association for Computational Linguistics},
	author = {Xu, Wei and Napoles, Courtney and Pavlick, Ellie and Chen, Quanze and Callison-Burch, Chris},
	urldate = {2021-11-03},
	date = {2016-07-01},
	keywords = {sari},
	file = {Xu et al_2016_Optimizing Statistical Machine Translation for Text Simplification.pdf:C\:\\Users\\alena\\Zotero\\storage\\3UQKHJI2\\Xu et al_2016_Optimizing Statistical Machine Translation for Text Simplification.pdf:application/pdf;Snapshot:C\:\\Users\\alena\\Zotero\\storage\\INVEULJ3\\Optimizing-Statistical-Machine-Translation-for.html:text/html},
}


@article{test,
	title = {Readability Standards for Informed-Consent Forms as Compared with Actual Readability},
	volume = {348},
	issn = {0028-4793},
	url = {https://doi.org/10.1056/NEJMsa021212},
	doi = {10.1056/NEJMsa021212},
	abstract = {Investigators found that although many institutional review boards advise researchers to write informed-consent forms at an 8th-grade reading level, the sample forms they provide are often written above the 10th-grade level. Readability was not associated with local rates of literacy.},
	pages = {721--726},
	number = {8},
	journaltitle = {New England Journal of Medicine},
	author = {Paasche-Orlow, Michael K. and Taylor, Holly A. and Brancati, Frederick L.},
	urldate = {2022-01-07},
	date = {2003},
	pmid = {12594317},
	note = {Publisher: Massachusetts Medical Society
	\_eprint: https://doi.org/10.1056/{NEJMsa}021212},
	file = {Paasche-Orlow et al_2003_Readability Standards for Informed-Consent Forms as Compared with Actual.pdf:C\:\\Users\\alena\\Zotero\\storage\\RIFV2HZY\\Paasche-Orlow et al_2003_Readability Standards for Informed-Consent Forms as Compared with Actual.pdf:application/pdf;Snapshot:C\:\\Users\\alena\\Zotero\\storage\\SNZTUWJ9\\NEJMsa021212.html:text/html},
}

@article{siddharthan_survey_2014,
	title = {A survey of research on text simplification},
	doi = {10.1075/ITL.165.2.06SID},
	abstract = {The goal of this paper is to summarise the large interdisciplinary body of work on text simplification and highlight the most promising research directions to move the field forward. Text simplification, defined narrowly, is the process of reducing the linguistic complexity of a text, while still retaining the original information and meaning. More broadly, text simplification encompasses other operations; for example, conceptual simplification to simplify content as well as form, elaborative modification, where redundancy and explicitness are used to emphasise key points, and text summarisation to omit peripheral or inappropriate information. There is substantial evidence that manual text simplification is an effective intervention for many readers, but automatic simplification has only recently become an established research field. There have been several recent papers on the topic, however, which bring to the table a multitude of methodologies, each with their strengths and weaknesses. The goal of this paper is to summarise the large interdisciplinary body of work on text simplification and highlight the most promising research directions to move the field forward.},
	author = {Siddharthan, Advaith},
	date = {2014},
}


@article{zhu_monolingual_2010,
	location = {Beijing, China},
	title = {A Monolingual Tree-based Translation Model for Sentence Simplification},
	url = {https://aclanthology.org/C10-1152},
	eventtitle = {{COLING} 2010},
	pages = {1353--1361},
	booktitle = {Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010)},
	publisher = {Coling 2010 Organizing Committee},
	author = {Zhu, Zhemin and Bernhard, Delphine and Gurevych, Iryna},
	urldate = {2022-01-07},
	date = {2010},
	file = {Zhu et al_2010_A Monolingual Tree-based Translation Model for Sentence Simplification.pdf:C\:\\Users\\alena\\Zotero\\storage\\7QARXBNM\\Zhu et al_2010_A Monolingual Tree-based Translation Model for Sentence Simplification.pdf:application/pdf},
}


@article{finegan_dollak_sentence_2016,
	title = {Sentence simplification, compression, and disaggregation for summarization of sophisticated documents},
	volume = {67},
	issn = {23301635},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/asi.23576},
	doi = {10.1002/asi.23576},
	pages = {2437--2453},
	number = {10},
	journaltitle = {J Assn Inf Sci Tec},
	author = {Finegan-Dollak, Catherine and Radev, Dragomir R.},
	urldate = {2021-10-27},
	date = {2016-10},
	langid = {english},
	file = {Finegan-Dollak_Radev_2016_Sentence simplification, compression, and disaggregation for summarization of.pdf:C\:\\Users\\alena\\Zotero\\storage\\8KP7EYHZ\\Finegan-Dollak_Radev_2016_Sentence simplification, compression, and disaggregation for summarization of.pdf:application/pdf},
}


@inproceedings{liu_simplification_2016,
	location = {Osaka, Japan},
	title = {Simplification of Example Sentences for Learners of Japanese Functional Expressions},
	url = {https://aclanthology.org/W16-4901},
	abstract = {Learning functional expressions is one of the difficulties for language learners, since functional expressions tend to have multiple meanings and complicated usages in various situations. In this paper, we report an experiment of simplifying example sentences of Japanese functional expressions especially for Chinese-speaking learners. For this purpose, we developed “Japanese Functional Expressions List” and “Simple Japanese Replacement List”. To evaluate the method, we conduct a small-scale experiment with Chinese-speaking learners on the effectiveness of the simplified example sentences. The experimental results indicate that simplified sentences are helpful in learning Japanese functional expressions.},
	pages = {1--5},
	booktitle = {Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications ({NLPTEA}2016)},
	publisher = {The {COLING} 2016 Organizing Committee},
	author = {Liu, Jun and Matsumoto, Yuji},
	urldate = {2021-11-03},
	date = {2016-12},
	keywords = {введение},
	file = {Liu_Matsumoto_2016_Simplification of Example Sentences for Learners of Japanese Functional.pdf:C\:\\Users\\alena\\Zotero\\storage\\J4JJ977Q\\Liu_Matsumoto_2016_Simplification of Example Sentences for Learners of Japanese Functional.pdf:application/pdf},
}


@article{sikka_survey_2020,
	title = {A Survey on Text Simplification},
	url = {http://arxiv.org/abs/2008.08612},
	abstract = {Text Simplification ({TS}) aims to reduce the linguistic complexity of content to make it easier to understand. Research in {TS} has been of keen interest, especially as approaches to {TS} have shifted from manual, hand-crafted rules to automated simplification. This survey seeks to provide a comprehensive overview of {TS}, including a brief description of earlier approaches used, discussion of various aspects of simplification (lexical, semantic and syntactic), and latest techniques being utilized in the field. We note that the research in the field has clearly shifted towards utilizing deep learning techniques to perform {TS}, with a specific focus on developing solutions to combat the lack of data available for simplification. We also include a discussion of datasets and evaluations metrics commonly used, along with discussion of related fields within Natural Language Processing ({NLP}), like semantic similarity.},
	journaltitle = {{arXiv}:2008.08612 [cs]},
	author = {Sikka, Punardeep and Mago, Vijay},
	urldate = {2021-11-03},
	date = {2020-08-24},
	eprinttype = {arxiv},
	eprint = {2008.08612},
	keywords = {Computer Science - Computation and Language},
	file = {Sikka_Mago_2020_A Survey on Text Simplification.pdf:C\:\\Users\\alena\\Zotero\\storage\\W64CWQ8P\\Sikka_Mago_2020_A Survey on Text Simplification.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\alena\\Zotero\\storage\\2544D53M\\2008.html:text/html},
}


@article{evans_evaluation_2014,
	location = {Gothenburg, Sweden},
	title = {An evaluation of syntactic simplification rules for people with autism},
	url = {https://aclanthology.org/W14-1215},
	doi = {10.3115/v1/W14-1215},
	pages = {131--140},
	booktitle = {Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations ({PITR})},
	publisher = {Association for Computational Linguistics},
	author = {Evans, Richard and Orăsan, Constantin and Dornescu, Iustin},
	urldate = {2021-11-03},
	date = {2014-04},
	keywords = {введение},
	file = {Evans et al_2014_An evaluation of syntactic simplification rules for people with autism.pdf:C\:\\Users\\alena\\Zotero\\storage\\4PQKMDAR\\Evans et al_2014_An evaluation of syntactic simplification rules for people with autism.pdf:application/pdf},
}


@article{kazan_federal_university,
	title = {{RuSimpleSentEval}-2021 Shared Task: Evaluating Sentence Simplification for Russian},
	url = {http://www.dialog-21.ru/media/5558/sakhovskiyaplusetal161.pdf},
	doi = {10.28995/2075-7182-2021-20-607-617},
	shorttitle = {{RuSimpleSentEval}-2021 Shared Task},
	abstract = {This report presents the results from the {RuSimpleSentEval} Shared Task conducted as a part of the Dialogue 2021 evaluation campaign. For the {RSSE} Shared Task, devoted to sentence simpliﬁcation in Russian, a new middlescale dataset is created from scratch. It enumerates more than 3000 sentences sampled from popular Wikipedia pages. Each sentence is aligned with 2.2 simpliﬁed modiﬁcations, on average. The Shared Task implies sequenceto-sequence approaches: given an input complex sentence, a system should provide with its simpliﬁed version. A popular sentence simpliﬁcation measure, {SARI}, is used to evaluate the system’s performance.},
	eventtitle = {Computational Linguistics and Intellectual Technologies},
	pages = {607--617},
	author = {{Kazan Federal University, Kazan, Russia} and Sakhovskiy, Andrey and Izhevskaya, Alexandra and {National Research University Higher School of Economics, Moscow, Russia} and Pestova, Alena and {National Research University Higher School of Economics, Moscow, Russia} and Tutubalina, Elena and {Kazan Federal University, Kazan, Russia} and Malykh, Valentin and {Kazan Federal University, Kazan, Russia} and Smurov, Ivan and {ABBYY, Moscow, Russia} and Artemova, Ekaterina and {National Research University Higher School of Economics, Moscow, Russia}},
	urldate = {2021-10-27},
	date = {2021-06-19},
	langid = {english},
	file = {Kazan Federal University, Kazan, Russia и др. - 2021 - RuSimpleSentEval-2021 Shared Task Evaluating Sent.pdf:C\:\\Users\\alena\\Zotero\\storage\\3JA4UQ33\\Kazan Federal University, Kazan, Russia и др. - 2021 - RuSimpleSentEval-2021 Shared Task Evaluating Sent.pdf:application/pdf},
}