\chapter{Классификация существующих решений (методов решения, алгоритмов)}

Описываются существующие решения, даются ссылки. Предлагаются критерии оценки методов. Хорошо, если критерии имеют обоснование. Приводится классификация решений по критериям в виде таблицы, но в отдельных случаях можно и не в виде таблицы (пример мы Вам кидаем отдельно от документа).

В данном разделе описываются существующие решения задчи упрощения текстов, предлагаются критерии оценки методов и приводится классификация решений по этим критериям.

\section{Существующие подходы}

Глобально выделяют два подхода к решению задачи упрощения текстов - экстрактивный (извлекающий) и абстрактный.

Большинство ранних работ, посвященных задаче упрощения текстов, использовали экстрактивный подход - выделение в документе тех предложений, которые передают больше информации. Этот подход достаточно прост в реализации, однако он подходит лишь для решения задачи упрощения текстов в широком смысле, поэтому в дальнейшем в данной работе рассматриваться не будет.

С ростом доступности вычислительных ресурсов и количества исследований в области NLP, для решения задачи упрощения текстов все чаще стал использоваться абстрактный подход, подразумевающий генерацию нового текста \cite{see_get_2017}. 

\section{Абстрактный подход}

Решения задачи упрощения текстов, относяшиеся к абстрактному подходу, можно глобально разделить на лексическое упрощение и генерацию нового текста.

Первоначально абстрактный подход подразумевал упрощение предложений за счет лексических замен на уровне слов или целых фраз \cite{paetzold_survey_2017}. Этот процесс фокусируется исключительно на сокращении лексического содержания текста, но не принимает во внимание такие подзадачи, как грамматическое или синтаксическое упрощение \cite{shardlow_survey_2014}. Таким образом, эти решения не учитывают все аспекты решаемой задачи и поэтому в дальнейшем рассматриваться не будут.

Современные решения, основанные на абстрактном подходе,  включают в себя разбиение корпуса на предложения, удаление и генерацию текста. Это стало возможным благодаря появлению нейронных сетей, в частности, рекуррентных нейронных сетей (RNNs)\footnote{Рекуррентная нейронная сеть, или RNN, - это сеть, которая работает с последовательностью и использут собственные промежуточные выходные данные в качестве входных данных для последующих шагов \cite{noauthor_nlp_nodate}}, которые позволяют решать задачи <<от последовательности к последовательности>> (seq2seq)\footnote{Сеть sequence-to-sequence (<<от последовательности к последовательсности>>), или сеть seq2seq, или сеть кодировщика-декодера, представляет собой модель, состоящую из двух RNN, называемых кодировщиком и декодером. Кодер считывает входную последовательность и выдает один вектор, а декодер считывает этот вектор для создания выходной последовательности \cite{noauthor_nlp_nodate}}.

Конвейер (?pipeline, не знаю, удачно ли подобран перевод) для этих подходов является универсальным, также довольно сложен. Предварительная обработка данных для моделирования seq2seq включает очистку входного и целевого текста, удаление знаков препинания и специальных символов, формирование словаря типичных слов. Далее входные и целевые предложения векторизуются в числовую форму для модели с вектором одинаковой длины либо путем усечения, либо путем заполнения. После того как модель была обучена, новая тестовая последовательность также сначала векторизуется, преобразуется к определенной длине и упрощается, а только после этого преобразовывается обратно из числовой формы в текстовую.


\section{Генерация нового текста}

Далее будут рассмотрены различные виды решений задачи упрощения текста с помощью генерации нового текста в рамках абстрактного подхода.

\subsection{Синтаксическое упрощение}







